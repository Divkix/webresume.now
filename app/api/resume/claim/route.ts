import { createClient } from '@/lib/supabase/server'
import {
  CopyObjectCommand,
  DeleteObjectCommand,
  GetObjectCommand,
  HeadObjectCommand,
} from '@aws-sdk/client-s3'
import { getSignedUrl } from '@aws-sdk/s3-request-presigner'
import { getR2Client, getR2Bucket } from '@/lib/r2'
import { parseResume } from '@/lib/replicate'
import { enforceRateLimit } from '@/lib/utils/rate-limit'
import {
  createErrorResponse,
  createSuccessResponse,
  ERROR_CODES,
} from '@/lib/utils/security-headers'
import {
  validatePDFMagicNumber,
  validateRequestSize,
  MAX_FILE_SIZE,
} from '@/lib/utils/validation'

/**
 * POST /api/resume/claim
 * Claims an anonymous upload and triggers AI parsing
 * Rate limit: 5 uploads per 24 hours
 */
export async function POST(request: Request) {
  try {
    // Initialize R2 client and bucket
    const r2Client = getR2Client()
    const R2_BUCKET = getR2Bucket()

    // 1. Validate request size before parsing (prevent DoS)
    const sizeCheck = validateRequestSize(request)
    if (!sizeCheck.valid) {
      return createErrorResponse(
        sizeCheck.error || 'Request body too large',
        ERROR_CODES.BAD_REQUEST,
        413
      )
    }

    const supabase = await createClient()

    // 2. Check authentication
    const {
      data: { user },
      error: authError,
    } = await supabase.auth.getUser()

    if (authError || !user) {
      return createErrorResponse(
        'You must be logged in to claim a resume',
        ERROR_CODES.UNAUTHORIZED,
        401
      )
    }

    // 3. Parse request body
    let body
    try {
      body = await request.json()
    } catch {
      return createErrorResponse(
        'Invalid JSON in request body',
        ERROR_CODES.BAD_REQUEST,
        400
      )
    }

    const { key } = body

    if (!key || !key.startsWith('temp/')) {
      return createErrorResponse(
        'Invalid upload key. Must be a temporary upload.',
        ERROR_CODES.VALIDATION_ERROR,
        400
      )
    }

    // 4. Rate limiting check (5 uploads per 24 hours)
    const rateLimitResponse = await enforceRateLimit(user.id, 'resume_upload')
    if (rateLimitResponse) {
      return rateLimitResponse
    }

    // 5. Generate new key
    const timestamp = Date.now()
    const filename = key.split('/').pop()
    const newKey = `users/${user.id}/${timestamp}/${filename}`

    // 6. Insert DB record - unique index prevents duplicates
    // The partial unique index on (user_id, filename) handles race conditions
    const { data: resume, error: insertError } = await supabase
      .from('resumes')
      .insert({
        user_id: user.id,
        r2_key: newKey,
        status: 'pending_claim',
      })
      .select()
      .single()

    // Handle race condition - if duplicate, fetch and return existing
    if (insertError?.code === '23505') {
      // Unique constraint violation - another request already claimed this file
      // Escape SQL wildcards in filename to prevent LIKE injection
      const escapedFilename = filename.replace(/[%_]/g, '\\$&')

      const { data: existingResume, error: fetchError } = await supabase
        .from('resumes')
        .select('id, status')
        .eq('user_id', user.id)
        .like('r2_key', `users/${user.id}/%/${escapedFilename}`)
        .neq('status', 'failed')
        .order('created_at', { ascending: false })
        .limit(1)
        .single()

      if (fetchError) {
        console.error('Failed to fetch existing resume after conflict:', fetchError)
        return createErrorResponse(
          'Upload conflict detected. Please try again.',
          ERROR_CODES.CONFLICT,
          409
        )
      }

      if (existingResume) {
        return createSuccessResponse({
          resume_id: existingResume.id,
          status: existingResume.status,
        })
      }
    }

    if (insertError) {
      console.error('Database insert error:', insertError)
      return createErrorResponse(
        'Failed to create resume record. Please try again.',
        ERROR_CODES.DATABASE_ERROR,
        500
      )
    }

    // Helper to mark resume as failed and return error
    const failResume = async (
      errorMessage: string,
      errorCode: string,
      statusCode: number
    ) => {
      await supabase
        .from('resumes')
        .update({ status: 'failed', error_message: errorMessage })
        .eq('id', resume.id)

      return createErrorResponse(errorMessage, errorCode, statusCode)
    }

    // 7. Validate file exists and check size (10MB limit)
    try {
      const headCommand = new HeadObjectCommand({
        Bucket: R2_BUCKET,
        Key: key,
      })
      const headResponse = await r2Client.send(headCommand)

      if (
        headResponse.ContentLength &&
        headResponse.ContentLength > MAX_FILE_SIZE
      ) {
        const sizeInMB = Math.round(headResponse.ContentLength / 1024 / 1024)
        return await failResume(
          `File size exceeds 10MB limit (${sizeInMB}MB)`,
          ERROR_CODES.VALIDATION_ERROR,
          400
        )
      }
    } catch (error) {
      console.error('File validation error:', error)
      // Generic error message to prevent enumeration of valid temp keys
      return await failResume(
        'Upload not found or expired. Please try uploading again.',
        ERROR_CODES.VALIDATION_ERROR,
        400
      )
    }

    // 8. Validate PDF magic number before processing
    const pdfValidation = await validatePDFMagicNumber(r2Client, R2_BUCKET, key)
    if (!pdfValidation.valid) {
      return await failResume(
        pdfValidation.error || 'Invalid PDF file',
        ERROR_CODES.VALIDATION_ERROR,
        400
      )
    }

    // 9. Copy object to user's folder
    try {
      await r2Client.send(
        new CopyObjectCommand({
          Bucket: R2_BUCKET,
          CopySource: `${R2_BUCKET}/${key}`,
          Key: newKey,
        })
      )
    } catch (error) {
      console.error('R2 copy error:', error)
      // Generic error message to prevent enumeration of valid temp keys
      return await failResume(
        'Upload not found or expired. Please try uploading again.',
        ERROR_CODES.VALIDATION_ERROR,
        400
      )
    }

    // 10. Delete temp object (best effort - not critical if fails)
    // Can be cleaned up by R2 lifecycle rules if this fails
    try {
      await r2Client.send(
        new DeleteObjectCommand({
          Bucket: R2_BUCKET,
          Key: key,
        })
      )
    } catch (error) {
      console.error('R2 delete error:', error)
      // Continue - temp file cleanup failure is not critical
    }

    // 11. Generate presigned URL for Replicate
    const getCommand = new GetObjectCommand({
      Bucket: R2_BUCKET,
      Key: newKey,
    })

    let presignedUrl: string
    try {
      presignedUrl = await getSignedUrl(r2Client, getCommand, {
        expiresIn: 3600, // 1 hour - sufficient for Replicate to fetch
      })
    } catch (error) {
      console.error('Presigned URL generation error:', error)
      return await failResume(
        'Failed to prepare file for processing',
        ERROR_CODES.EXTERNAL_SERVICE_ERROR,
        500
      )
    }

    // 12. Trigger Replicate parsing with webhook
    let replicateJobId: string | null = null
    let parseError: string | null = null

    // Build webhook URL for Replicate to call when done
    const appUrl = process.env.NEXT_PUBLIC_APP_URL
    const webhookUrl = appUrl ? `${appUrl}/api/webhook/replicate` : undefined

    try {
      const prediction = await parseResume(presignedUrl, webhookUrl)
      replicateJobId = prediction.id
    } catch (error) {
      console.error('Failed to trigger Replicate parsing:', error)
      parseError =
        error instanceof Error ? error.message : 'Failed to start AI parsing'
    }

    // 13. Update resume with replicate job ID or error
    const updatePayload: {
      status: 'processing' | 'failed'
      replicate_job_id?: string
      error_message?: string
    } = replicateJobId
      ? {
          status: 'processing',
          replicate_job_id: replicateJobId,
        }
      : {
          status: 'failed',
          error_message: parseError || 'Unknown error',
        }

    const { error: updateError } = await supabase
      .from('resumes')
      .update(updatePayload)
      .eq('id', resume.id)

    if (updateError) {
      console.error('Failed to update resume with replicate job:', updateError)
      // Continue anyway - status endpoint will handle it
    }

    return createSuccessResponse({
      resume_id: resume.id,
      status: updatePayload.status,
    })
  } catch (error) {
    console.error('Error claiming resume:', error)
    return createErrorResponse(
      'An unexpected error occurred while claiming your resume',
      ERROR_CODES.INTERNAL_ERROR,
      500
    )
  }
}
