import { parseWithAi } from "./ai-parser";
import { extractPdfText } from "./pdf-extract";
import { resumeSchema } from "./schema";
import { transformAiOutput, transformAiResponse } from "./transform";

export interface ParseResumeResult {
  success: boolean;
  parsedContent: string;
  error?: string;
}

const MAX_RESUME_TEXT_CHARS = 60000;
const RESUME_HEAD_CHARS = 38000;
const RESUME_TAIL_CHARS = 18000;
const RESUME_TRUNCATION_MARKER = "\n\n...[truncated]...\n\n";

function normalizeResumeText(text: string): string {
  return text
    .replace(/\r\n/g, "\n")
    .replace(/[ \t]{2,}/g, " ")
    .replace(/\n{3,}/g, "\n\n")
    .trim();
}

function truncateResumeText(text: string): string {
  if (text.length <= MAX_RESUME_TEXT_CHARS) return text;
  const head = text.slice(0, RESUME_HEAD_CHARS);
  const tail = text.slice(-RESUME_TAIL_CHARS);
  return `${head}${RESUME_TRUNCATION_MARKER}${tail}`;
}

/**
 * Parse a PDF resume using AI
 *
 * Pipeline:
 * 1. Extract text from PDF using unpdf
 * 2. Parse text with AI using Vercel AI SDK (structured output)
 * 3. Transform and validate the AI response
 * 4. Return JSON string of parsed content
 *
 * Accepts ArrayBuffer directly from R2 to avoid intermediate buffer copies.
 */
export async function parseResumeWithAi(
  pdfBuffer: ArrayBuffer,
  env: Partial<CloudflareEnv>,
): Promise<ParseResumeResult> {
  try {
    // Step 1: Extract text from PDF â€” pass ArrayBuffer directly, no copies
    const extractResult = await extractPdfText(pdfBuffer);

    if (!extractResult.success || !extractResult.text) {
      return {
        success: false,
        parsedContent: "",
        error: extractResult.error || "PDF extraction failed",
      };
    }

    const normalizedText = normalizeResumeText(extractResult.text);
    const resumeText = truncateResumeText(normalizedText);

    if (!resumeText.trim()) {
      return {
        success: false,
        parsedContent: "",
        error: "Extracted resume text is empty",
      };
    }

    // Step 2: Parse with AI
    const parseResult = await parseWithAi(resumeText, env);

    if (!parseResult.success || !parseResult.data) {
      return {
        success: false,
        parsedContent: "",
        error: parseResult.error || "AI parsing failed",
      };
    }

    // Step 3: Transform - lenient validation with XSS protection
    const transformedData = transformAiResponse(parseResult.data);

    // Step 4: Default missing array fields for fallback path (no schema enforcement)
    const withDefaults = transformedData as Record<string, unknown>;
    for (const key of ["education", "skills", "certifications", "projects"]) {
      if (!Array.isArray(withDefaults[key])) withDefaults[key] = [];
    }

    // Step 5: Validate against schema
    const validationResult = resumeSchema.safeParse(withDefaults);
    if (!validationResult.success) {
      return {
        success: false,
        parsedContent: "",
        error: "AI response failed schema validation",
      };
    }

    // Step 6: Final cleanup
    const finalData = transformAiOutput(validationResult.data);

    return {
      success: true,
      parsedContent: JSON.stringify(finalData),
    };
  } catch (error) {
    return {
      success: false,
      parsedContent: "",
      error: error instanceof Error ? error.message : "Unknown error",
    };
  }
}
